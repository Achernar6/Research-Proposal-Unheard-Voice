# Unheard Voices, Market Signals: Decoding the Causal Mechanisms and Predictive Power of Silence on Financial Social Media

- ## Research Background
- Alongside the digitalization of financial markets, there has been a surge in information-driven events and a corresponding trend in leveraging public discourse from social media and news to predict the market. Market researchers increasingly attempt to measure and trade on investor sentiment beyond simple message volume, believing opinion can be a leading indicator of asset price movements, a potential that was highlighted in early work like [When Can Social Media Lead Financial Markets?-2014](https://pmc.ncbi.nlm.nih.gov/articles/PMC5379406/). This approach seeks to transform unstructured public discourse into quantifiable signals with predictive power.
- However, among this trend of leveraging public discourse for market prediction, several limitations have emerged. First, the data itself is noisy; as the study [Unleashing Expert Opinion from Social Media for Stock Prediction-2025](https://arxiv.org/html/2504.10078v1) found, raw aggregated sentiment from platforms like StockTwits had a predictive accuracy worse than random guessing. Second, a significant body of research now shows that the causal relationship between discourse and market movement is not a simple one-way street, but rather **a complex, bidirectional feedback loop**. Works like [Stories that (are) Move(d by) Markets-2025](http://arxiv.org/pdf/2502.14497.pdf) describe it as a “mutually reinforcing cycle,” a finding supported by multiple methodologies from information-theoretic measures ([Information Theoretic Causality Detection-2021](https://www.mdpi.com/1099-4300/23/5/621)) to classic Granger-causality tests ([Market Trend Prediction using Sentiment Analysis-2018](https://www.semanticscholar.org/paper/4ee35ee54913eb31af5d5ea1a664b6c75be4b9b9)), demonstrating how this complex causality fundamentally interferes with prediction. This suggests a growing need to move beyond simple causality tests toward a framework that can model the causal interplay between a broader range of market, social, and individual-level factors. Finally, predictive models are also hindered by the **complexity of opinion dynamics and the nuance of sentiment**. Simple aggregation often fails because the predictive power of sentiment is not uniform; as work like [Limitations of News Sentiment Analysis in Short-term Stock Return Prediction-2025](https://www.linkedin.com/posts/ga%C3%ABl-kengmegni-345474130_limitations-of-news-sentiment-analysis-in-activity-7285629672447508480-jChI) demonstrates; The target of sentiment also matters -- broader market-level sentiment can be more influential than stock-specific signals, as [Market Trend Prediction using Sentiment Analysis: Lessons Learned and Paths Forward-2018](https://www.semanticscholar.org/paper/4ee35ee54913eb31af5d5ea1a664b6c75be4b9b9) already flagged. In response, the field is actively developing more sophisticated techniques, like [An Innovative Sentiment Influenced Stock Market Prediction Based on Dual Scale Adaptive Residual Long Short Term Memory With Attention Mechanism-2025](https://onlinelibrary.wiley.com/doi/10.1111/coin.70073) proposing novel architectures to better integrate these intricate sentiment dynamics with financial data. Ultimately, these challenges and directions point toward **a convergence with methodologies from computational social science** (CSS), which has long emphasized that a true understanding of public discourse requires analyzing both social structure and semantic content, proposing the integration of social network and social representations with the biparty network [Two Sides of the Same Coin-2024](https://social-dynamics.net/docs/SNA_SemNA_final_preprint.pdf), and the semantic continuity of topic [Can Large Language Models Transform Computational Social ...-2024](https://direct.mit.edu/coli/article/50/1/237/118498/Can-Large-Language-Models-Transform-Computational) and the nuance of sentiments [Semantic Component Analysis: Discovering Patterns in Short Texts Beyond Topics-2024](https://arxiv.org/html/2410.21054)[Sentimental Insight 2.0: Exploring the Frontiers of Opinion Mining with Deep Learning-2024](https://ieeexplore.ieee.org/document/10515707/)
- But among this convergence, a theme that has been constantly under the spotlight of CSS yet remains largely unexamined in computational finance--**the silent majority**--the vast cohort of users who consume information but stay completely or selectively silent due to personal habits or self-censorship. While CSS has explored these hidden opinions, computational finance has traditionally focused almost exclusively on the **positively observed voices**, treating silence as an absence of information rather than a form of it.
- In recent years, computational finance academia has paid growing yet limited attention to this inconspicuous silence, and has preliminarily found it holds importance. As demonstrated in [How Does Social Media Impact Bitcoin Value? A Test of the Silent Majority Hypothesis-2017](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2545957), the sentiment of the less-active "silent majority" was a more powerful predictor of Bitcoin's future value than posts from the vocal minority. This finding was echoed in [The Neglected Cohort: The Impact of Silent Majority in Social Media on Stock Returns-2022](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4179731), which identified the "Neglected Cohort" of silent users whose collective sentiment had a significantly greater impact on stock returns. Other work, such as [Distilling wisdom of crowds in online communities-2024](https://www.sciencedirect.com/science/article/abs/pii/S016792362400023X), has indirectly leveraged quieter participants by designing mechanisms to filter out underperforming traders.
- Though these studies have discovered a new and promising scope of research, t**heir methodology reveals a significant gap**. They almost universally rely on a static, binary division between "silent" and "active" users, often based on a simple threshold of posting frequency. This absolute division is misaligned with the nuanced, contextualized, and dynamic direction the field is heading. Silence is not a fixed trait but a context-dependent behavior; a user may be silent on one topic but vocal on another, and their choice to remain silent can be as informative as a vocal opinion. This binary approach fails to capture the mechanisms behind silence or its evolution over the course of an event.
- Toward this end, we have identified a neglected direction in the study of silence and a methodological gap in how it is examined. The full potential of the silent majority as a predictive force cannot be unlocked by treating them as a monolithic, static block. This work will therefore examine the formation mechanism of silence and its predictive power, moving beyond a simple binary to a dynamic and multi-faceted analysis. To achieve this, this work examines **causality both "to" and "from" the silence** by extracting rich features from individual, market, and SNS data to examine the **interplay between these contextual factors** and the **predictive power of inferred stance from the silence**, all on the foundation of a holistic understanding of an event's evolution.
-
- ## Research Aim and Questions
- ### Research Aim
  The main objective of this study is to enhance financial market prediction by leveraging the predictive information within the "silent majority" on social media, developing and validating a novel framework to identify, explain the silence and its mechanisms, infer what's under the silence, examine the predictive power of the inferred, all on the foundation of a holistic, dynamic understanding of the whole event's evolution.  
- ### Research Questions
  To achieve this aim, we propose the following research questions:  
- **RQ1: Identification of Silence within its Context.**  How to define and capture the silence within an individual's social participation pattern under a broader network context?
- **RQ2: The Formation Mechanism of Silence.** What are the key factors—across individual attributes and performance, social network dynamics, and market conditions—that drive an individual's decision to turn silent during an event?
- **RQ3: Inference of Different Case of Silence.** How can the causal factors identified in RQ2 be used to infer the latent sentiment or stance of the silent majority? What cases of silence can we aggregate from RQ2's result? How does it differ from the explicitly stated views of the vocal minority through the whole event?
- **RQ4: The Predictive Power of Inferred Silence.** Does the inferred stance and sentiment from the silence show significant predictive power for future market movements? Does it outperform models that rely solely on sentiment from the positively observed dataset?
-
- ## Research Method
- **1- Event Curation, Data acquisition**
	- select a suitable target event and period of study, which align with current challenges (e.g. the memestock)
	- Platform selection:
		- the event's discussion should be taken on a platform with rich data source, better with both social participation and transaction data, with rich demographics and past performance.
	- Time window selection:
		- The time window should cover the target topic's range, but expand a little bit to capture the "normal" pattern of each investor's social interaction habit.
- ### 2- Holistic Event Reconstruction
	- To set the foundation for a well-contextualized understanding of the silence, this section creates rich, comprehensive dataset spanning from micro to macro, capturing the silence.
	- ### 2.1- Micro-Macro Level Feature Engineering
	- To go beyond treating SNS discussions as pure stream of text, we mine rich features from individual and market, also with SNS factors broken down into three interconnected factors: what users talk about (topics), how they feel about it (topic-specific stance and sentiment), and who they talk with (interaction defined community), from both micro and macro perspective.
	-
	- **2.1.1- Micro-Level Features: The Individual's Footprint**
	  These are features unique to each individual user, reflecting their personal trading history, topic-specific beliefs and position in the community(both content defined and interaction defined).  
	- **Financial Micro-Features (Personal Performance):** When available (on certain forums), we will incorporate user-specific transaction data to create features reflecting their personal financial status and trading performance. This includes metrics like historical portfolio returns, trading frequency, and realized profit/loss.
	- **Social Micro-Features (Expressed Beliefs and Position):**
		- **Aspect-Based Sentiment (Positively observed) Profile:** We will engineer a nuanced sentiment profile for each user by applying Aspect-Based Sentiment Analysis (ABSA) as proposed by [FinXABSA: Explainable Finance through Aspect-Based Sentiment Analysis-2023](https://arxiv.org/pdf/2303.02563.pdf). This transforms their semantic posting history into a time series of multi-dimensional sentiment vectors with financial domain specialization like *'earnings'*, *'volatility'*, or *'management'*. Also, this could serve directly as the positively observed sentiment sequence to benchmark against later inferred sentiments, as well as serve as a baseline factor for predictive power evaluation.
		- **Thematic Engagement:** After detecting topic emergence using BERTopic as in [BERTopic: Neural topic modeling with a class-based TF-IDF procedure-2022](https://arxiv.org/abs/2203.05794) , we will track each user's engagement history with specific topics, aggregating into topic-specific participation activeness time series. In later macro features' section we have corresponding topic-level aggregation.
		- **Network Position and Role:** We will identify each user's structural position within the social network, extracting features like their network distance to key figures and their evolving role (e.g., core spreader, bridge) based on the methods from [A classification and recognition algorithm of key figures in public opinion integrating multidimensional similarity and K-shell based on supernetwork-2024](https://www.nature.com/articles/s41599-024-02711-4).
	- **2.1.2- Macro-Level Features: The Environmental Context**
	  This layer captures the global environmental variables that all users are exposed to, representing the collective social and market climate.  
	- **Macro-Market Environment:** We will incorporate key market-wide time series data that defines the overall financial climate. This includes:
		- The price and volume series of the underlying asset.
		- Broader market indices (e.g., S&P 500) to control for systemic trends.
		- A market volatility index (e.g., VIX) (as a measure of aggregate fear or uncertainty).
		- Market regime indicators (e.g., identifying "bull" vs. "bear" periods using moving averages).
	- **Macro-Social Environment (The Discourse Climate):** We will model the collective social environment using the two complementary network types proposed in *Two Sides of the Same Coin* (2024)1: interaction-based and topic-based networks.
		- **Topic and Sentiment Dynamics:** After detecting each topic's emergence with BERTopic, we will track the aggregate prevalence of topics, the average aspect-based topic-specific sentiment and overall polarization within the entire community or specific "topic circles," as analyzed in [Dissemination characteristics and influencing factors of topic circles-2025](https://www.frontiersin.org/journals/public-health/articles/10.3389/fpubh.2025.1566746/full).
		- **Network Structural Properties:** We will compute global network metrics such as density, modularity, and sentiment polarization to quantify the overall cohesion or fragmentation of the discourse.
	- **2.1.3- Representation and Visualization**
	  The analytical power of this framework comes from integrating these layers. Our visualizations will now explicitly bridge the micro and macro worlds:  
		- **Dynamic Network Graphs:** Node color can represent a user's *micro* sentiment on 'volatility', while the graph's background color represents the *macro* market regime (e.g., a red background during high VIX periods).
		- **Chord Diagrams:**
			- Actor-Actor Chord Diagram: Illustrates how interaction connection between users change over the lifecycle of the event.
			- Actor-Content Chord Diagram: Illustrates how the focused topic of users change over the lifecycle of the event.
		- **Layered Time-Series Plots:** We can selectively overlay different time-series data's time plot to gain longitude understanding of the event. For example:
			- overlaying individual's participation activeness, sentiment and stance series against the macro average topic climate and overall polarization score, to see how an individual turn silent/active due to the opinion (mis)alignment with the collective;
			- overlaying different topics' prevalence of a community to see its how its attention drifts;
			- overlaying an individual's trading performance, participation activeness and sentiment series against the overall market price to see how an investor turn silent having its expectations being failed by the market fact.
			- (some of these are unproved expected outcome about the qualitative mechanism of silence)
	- **2.1.4- Aggregated Feature Set for Downstream Modeling**
	  The output of this section is a comprehensive, time-resolved feature set for each user and overall environment:  
		- **Micro-Level Features:** Personal P&L, aspect-sentiment vectors, topic engagement history, network role.
		- **Macro-Level Features:** Market price/volatility, market regime, topic circle polarization, community sentiment.
	- By systematically engineering and separating features at both the micro and macro scales, we create a robust foundation to later stages.
	-
	- ### 2.2- Identifying Silencing Events: A Hybrid Anomaly Detection Framework
	- To effectively analyze the mechanisms of silence (RQ2), we must first precisely identify its occurrence (RQ1). Silence is not merely an absence of activity but a significant deviation from an expected pattern of participation. However, "expected" has two components: a user's own established habits (a temporal pattern) and the behavior of their social peers (a spatio-temporal pattern). To capture both, we will implement and evaluate a hybrid anomaly detection framework that uses two complementary lenses.
	-
	- **2.2.1- Lens 1: Temporal Anomaly Detection via Self-Comparison**
	  This first lens focuses on detecting when a user's activity deviates significantly from their *own* historical baseline. This is crucial for identifying personal shifts in behavior, independent of the wider community.  
	- **Methodology:** We will model each user’s topic-specific participation history as a temporal event sequence. We then employ a **Sequence-to-Sequence Variational Autoencoder (VAE)** with LSTM layers. This unsupervised deep learning model learns a compressed representation of a user's "normal" activity patterns. As proposed in your draft, anomalies are identified by a high reconstruction error—the model's inability to accurately reproduce the observed sequence from its learned representation of normalcy. We may enhance this by nesting a classifier layer to create a more direct outlier detection method, as explored in works like [Nested Binary Classifier as an Outlier Detection Method in Human Activity Recognition Systems-2021](https://pubmed.ncbi.nlm.nih.gov/34191728/).
	- **Advantages:** This temporal-only approach is computationally efficient as it processes each user's time series independently. It is hypothesized to be highly effective at detecting strong, unambiguous shifts in individual user habits.
	-
	- **2.2.2- Lens 2: Spatio-Temporal Anomaly Detection via Social Comparison**
	  A user's silence can also be defined by its deviation from their social context. For instance, a user staying silent while their entire community erupts in discussion is a socially significant anomaly that a purely temporal model might miss. This second lens identifies anomalies by comparing a user's activity to the expected behavior *given their position in the network*.  
	- **Methodology:** To capture this, we will implement a **Graph Neural Network (GNN)-based Anomaly Detection** model. This state-of-the-art approach is specifically designed to model the interplay between node attributes and graph structure over time. Following recent surveys like [A Comprehensive Survey on Graph Anomaly Detection with Deep Learning-2022](https://arxiv.org/abs/2202.09802), our implementation will:
		- Represent users as nodes in a dynamic graph where attributes are their multivariate feature time series from Section 2.1.
		- Use a GNN architecture (e.g., a Graph Autoencoder) to learn a model of normal spatio-temporal behavior, predicting each user's future activity based on their own past behavior *and* the aggregated behavior of their influential neighbors.
		- Detect an anomaly when a user's actual activity significantly deviates from this socially-contextualized prediction.
	- **Advantages:** While more computationally intensive, this method is hypothesized to capture subtle, context-dependent anomalies that are invisible to a user-centric model, making it essential for testing social theories like the spiral of silence.
	    
	  **2.2.3- A Unified Framework for Defining Silence**  
	  These two methodologies are not competitors for a single task but complementary tools for a more nuanced analysis. Their relationship will be defined as follows:  
	- **Hypothesis and Evaluation:** We hypothesize that the VAE model will excel at detecting **personal anomalies** (deviations from self), while the GNN model will excel at detecting **social anomalies** (deviations from group context). In our preliminary experiments, we will evaluate both models on their ability to generate features that correlate with known social and market events. Based on these results, we will decide whether to proceed with one method (if its superiority is overwhelming) or, more likely, to use both in concert.
	- **Complementary Integration:** If we proceed with both, we will generate two separate anomaly scores for each user at each time step. This allows for a richer categorization of silence:
		- **Personal Silence:** High VAE score, low GNN score (e.g., a user goes on vacation).
		- **Social Silence:** Low VAE score, high GNN score (e.g., a user fails to join a community discussion they normally would).
		- **High-Confidence Silence:** High scores from both models, indicating a behavior that is both personally uncharacteristic and socially deviant.
	- **2.2.4- Visualization and Feature Aggregation for Downstream Tasks**
	  This dual-lens approach enriches our ability to interpret and utilize the detected anomalies.  
	- **Visual Analysis:** We will enhance our visualizations from Section 2.1. For instance, network graphs can use node borders to indicate a personal anomaly and node halos to indicate a social anomaly, as proposed in visual analytics frameworks like [EventAction-2021](https://vaclab.unc.edu/publication/tvcg_2021_guo/tvcg_2021_guo.pdf), allowing for immediate identification of different silence patterns.
	- **Extracted Features:** This process yields a refined set of features for the causality analysis in Section 2.3:
		- **Personal Anomaly Score:** From the VAE.
		- **Social Anomaly Score:** From the GNN.
		- **Combined Anomaly Flag:** A categorical feature indicating the type of anomaly detected.
	- By operationalizing silence through this robust, dual-lens framework, we create a solid empirical foundation to investigate its causes and consequences.
	-
	- ### 2.3- Causal Mechanism Discovery: Uncovering the Drivers of Silence
	    
	  Having identified topic-specific silencing events as anomalies in user activeness (RQ1), the next step is to understand their cause. To address **RQ2: The Formation Mechanism of Silence**, we must move beyond simple correlation to uncover the causal factors leading to an individual's decision to become silent. This requires a causal discovery framework coping with the high-dimensional, time-lagged, and nonlinear relationships inherent in our dataset. Our approach will systematically test the influence of contextual factors (individual attributes, network dynamics, and market conditions) on a silencing event.  
	    
	  **2.3.1- A Two-Stage Framework for Causal Discovery**  
	- To robustly infer causal relationships from our complex, time-resolved data, we will employ a two-stage methodology that combines the strengths of graphical causal modeling and information-theoretic measures.
	- **Stage 1: Causal Graph Inference with PCMCI**
	  First, we will use the **Peter and Clark Momentary Conditional Independence (PCMCI)** algorithm to reconstruct a high-level causal graph. PCMCI is exceptionally well-suited for our scenario as it is designed for high-dimensional time-series data, can effectively handle time lags between cause and effect, and is robust to the influence of unobserved common drivers (confounders), a common challenge in financial systems. The input to the PCMCI algorithm will be a multivariate time series for each user, comprising the features extracted in sections 2.1 and 2.2:  
		- **Individual-level features:** Anomaly scores, role transitions, past performance, etc.
		- **Network-level features:** Community polarization, distance to key figures, local network density, etc.
		- **Topic-level features:** Topic prevalence, sentiment volatility, content polarization, etc.
		- **Market-level features:** Price volatility, trading volume, market regime, etc.
	- The output will be a directed graph illustrating the causal links between these factors and the detected silencing anomalies. For instance, the graph might reveal that a sharp increase in market volatility (market factor) followed by a rise in network polarization (network factor) causally precedes a user's silencing event (individual outcome). As recommended by recent comprehensive reviews like [Comprehensive Review and Empirical Evaluation of Causal ... - arXiv-2024](https://arxiv.org/html/2407.13054v1).
	- **Justification and further consideration:** We chose PCMCI because we’re confident our dataset includes a wide and rich set of features that cover most of the important factors behind silencing events. PCMCI works well for high-dimensional time series like ours, as long as we have the key variables. If, during our analysis, we notice odd or unstable causal links—suggesting some important drivers might be missing—we’ll try tsFCI, which is better at handling hidden confounders and can give us a more reliable causal structure in those cases.
	- **Stage 2: Quantifying Information Flow with Unified Information-Theoretic Causality (UIC)**
	  While PCMCI identifies the existence and direction of causal links, we next need to quantify their strength. For this, we will employ **Unified Information-Theoretic Causality (UIC)** on the significant links identified by the causal graph. As proposed in [Unified understanding of nonparametric causality detection in time series-2023](https://www.biorxiv.org/content/10.1101/2023.04.20.537743v2.full.pdf), UIC is a state-of-the-art nonparametric method that robustly quantifies information flow in both linear and nonlinear systems, outperforming traditional methods like Transfer Entropy, especially in the presence of noise and confounders. This will allow us to measure how much predictive information a specific driver (e.g., network sentiment) provides about a silencing event, gaining us a more quantitative understanding.  
	    
	  **2.3.2- Mechanism Categorization and Hypothesis Validation**  
	- The causal discovery process will produce a rich, evidence-based foundation for categorizing different types of silence. By analyzing the recurring patterns in the inferred causal graphs, we can group silencing events into distinct mechanisms. For example (these are just expected outcomes):
	- **Fear-Driven Silence:** Causally linked to sharp increases in market volatility and negative sentiment from key figures.
	- **Conformity-Driven Silence (Spiral of Silence):** Causally linked to high network polarization and a user's deviation from the dominant sentiment within their local interaction-based community.
	- **Attention-Shift Silence:** Causally linked to the decline of a subtopic's prevalence and the emergence of a new, competing topic.
	    
	  This data-driven categorization directly informs **RQ3 (Inference and Dynamics of Silent Stance)** by providing a foundation for designing mechanism-specific stance inference models in the next stage. For example, a silence caused by social conformity suggests a different inferential approach (e.g., collaborative filtering) than one driven by an external market shock. This step ensures our subsequent analyses are grounded in a validated understanding of user behavior.  
- ### 3- Latent Stance and Sentiment Inference
	- The causal discovery analysis in Section 2.3 provides the crucial link between *why* a user becomes silent and *how* we can infer their latent stance. Having categorized silencing events by their underlying drivers, we can now move beyond one-size-fits-all methods and design tailored inference models for different mechanisms. This section directly addresses **RQ3: Inference and Dynamics of Silent Stance** by focusing on two prominent and theoretically grounded cases of silence. For each, we will deploy a specialized inference methodology to predict the sentiment of silent users, creating enriched datasets for the final predictive evaluation stage.
	    
	  **3.1- Designing Mechanism-Specific Inference Models**  
	    
	  We will develop and implement distinct stance inference models for two exemplary silence mechanisms, chosen for their prevalence in social dynamics and financial behavior.  
	    
	  **Case 1: The Spiral of Silence (Conformity-Driven Silence)**  
	- **Mechanism:** This case corresponds to silencing events causally linked to network polarization and social pressure. A user falls silent when their personal opinion conflicts with the dominant sentiment of their immediate, interaction-based community. As foundational work on the spiral of silence suggests, this behavior is often driven by a fear of social isolation, prompting users to self-censor rather than voice a dissenting view[1](http://xlab.berkeley.edu/research/Conference_papers/yuen_paper.pdf)[2](https://www.emerald.com/insight/content/doi/10.1108/intr-03-2024-0413/full/pdf?title=supporting-opinions-to-fit-in-a-spiral-of-silence-theoretic-explanation-for-establishing-echo-chambers-and-filter-bubbles-on-social-media). Our causality analysis in Section 2.3 will have identified these instances by finding strong causal links from metrics like local community sentiment and network polarization to a user's silencing anomaly.
	- **Inference Method: Collaborative Filtering on Topic-Based Communities**
	  To infer the stance of a user silenced by social pressure, we will leverage **collaborative filtering**, a technique proven effective for this exact challenge. The core hypothesis is that while a user may be silenced by their *interaction-based* social circle, their true, unexpressed stance likely aligns with their *content-based* ideological peers—other users who engage with the same specific topics and subtopics, even if they do not interact directly.  
	    
	  The model will be implemented as follows:  
		- For a user identified as being in a "spiral of silence," we will ignore the sentiment of their immediate, vocal interaction network (which caused the silence).
		- Instead, we will identify a set of "ideological neighbors" from the topic-based bipartite network constructed in Section 2.1. These are users who have a similar history of engaging with the same niche subtopics.
		- The silent user’s latent stance will be inferred by aggregating the expressed stances of these topic-based neighbors. This approach, which separates social structure from ideological alignment, is exemplified in the state-of-the-art work by Bhattacharya et al. (2024), who combine collaborative filtering with graph-based learning to successfully unveil the stances of passive users[File Attachment].
	- **Case 2: Belief-Signal Divergence (Confidence-Driven Silence)**
	- **Mechanism:** This case, which we term "Belief-Signal Divergence," describes users who fall silent after receiving public information that sharply contradicts their strongly held prior beliefs. Rather than updating their opinion, these investors may discount the credibility of the new signal and withdraw from the discussion, holding onto their original conviction. For instance, a long-term bull on a stock may go silent after a surprisingly poor earnings report, not because they have become bearish, but because they believe the report is misleading or anomalous. This phenomenon is well-documented in behavioral finance, where investors are shown to react differentially to signals based on how those signals conform to their priors[3](https://faculty.wharton.upenn.edu/wp-content/uploads/2019/08/On_Diverging_Beliefs_In_Financial_Markets.pdf). Our causality analysis will flag these events by linking a silencing anomaly to a significant market event (e.g., price shock, news release) that conflicts with the user’s established posting history.
	- **Inference Method: Bayesian Belief Updating with Signal Precision Estimation**
	  Since this mechanism is rooted in individual cognition rather than social influence, a network-based method is unsuitable. We will instead employ a **Bayesian belief updating model** for each user. This model formally captures how an agent's belief (posterior) is a function of their prior conviction and the new evidence they receive.  
	    
	  The model will be implemented as follows:  
		- A user's **prior stance** will be established from their posting history *before* the silencing event.
		- The public **signal** (e.g., a specific news article, a market price change) that our causal analysis identified as the trigger will be quantified.
		- Crucially, we will model the user’s subjective assessment of the signal’s **precision**. Following the theory in [Financial Information and Diverging Beliefs], we hypothesize that the more a signal deviates from the user's prior, the lower the precision they will assign to it[3](https://faculty.wharton.upenn.edu/wp-content/uploads/2019/08/On_Diverging_Beliefs_In_Financial_Markets.pdf).
		- The user's inferred silent stance (their posterior belief) will be calculated. In cases of high divergence, the model will predict that the user's stance remains largely unchanged from their prior, reflecting their decision to reject the new information and fall silent. This aligns with behavioral models of investor panic and emotional response to market volatility[4](https://www.financialplanningassociation.org/sites/default/files/2021-10/FEB18%20JFP%20Wendel%20PDF.pdf).
		    
		  **3.2- Implementation and Enriched Dataset Creation**  
		    
		  The two models described above will be applied to their corresponding sets of silent users, as categorized by the causality analysis. The output will be a time-series of inferred stances (e.g., bullish, bearish, neutral) for each silent user. This inferred data will then be aggregated and combined with the observed data from vocal users to create several new, enriched sentiment datasets. These datasets will form the basis for the predictive power evaluation in the final stage of our research.  
		    
		  **3.3- Visualized Comparison with Observed Discourse**  
		    
		  To qualitatively assess the impact of the silent majority and validate our inferences, we will repeat the visualization process from Section 2.1. By **overlaying the inferred sentiment** of the silent majority onto the time-series plots and network graphs of vocal sentiment, we can create a more complete picture of the true opinion climate. These visualizations will allow us to intuitively compare the dynamics of the vocal minority against the hidden tide of silent opinion, providing a powerful qualitative check on our findings before proceeding to the quantitative prediction tasks in RQ4.  
	-
- ### 4- Predictive Power Evaluation
	- Having developed alternative sentiment datasets by inferring the stances from the silence, the final stage of this research is to rigorously evaluate their predictive utility. This section addresses **RQ4: The Predictive Power of Inferred Silence** by systematically testing whether these new sentiment factors can improve the prediction of future market movements compared to models that rely only on traditional data or sentiment from vocal users.
	-
	- **4.1- Experimental Setup for Market Prediction**
	- To isolate the contribution of our inferred sentiment, we will conduct a series of controlled forecasting experiment. We will follow the validation framework used in [Decoding Financial Markets: Unleashing the Power of Bi-LSTM in Sentiment Analysis for Cutting-Edge Stock Price Prediction-2023](https://ieeexplore.ieee.org/document/ 10392444/), developing a series of predictive models using a standard deep learning architecture, such as a Bidirectional LSTM (Bi-LSTM), which has proven effective for modeling sequential financial data and integrating sentiment signals, aligning with this study's scenario. The models will be trained to predict key market metrics, such as the next day's stock price direction.
	    
	  The experiment will compare the following models:  
	- **Baseline Model:** Trained only on traditional market data (e.g., historical prices, volume) and the contextual features generated in Section 2 (individual, network, and topic features).
	- **Vocal Sentiment Model:** The Baseline Model augmented with the positively observed sentiment factor from the FinXABSA outputs.
	- **Inferred Sentiment Models:** Multiple separate models augmenting the Baseline with each of our inferred sentiment dataset.
	- **Combined Model:** The Baseline Model augmented with all available sentiment factors (vocal and both inferred categories).
	-
	- **4.2- Evaluation Framework and Metrics**
	- A model's performance will be assessed using a backtesting framework based on **walk-forward validation**, training the model on a rolling window of past data and testing it on the subsequent period, preventing lookahead bias and simulates a realistic scenario.
	-
	- We will evaluate the models using two distinct criteria as in [Markets: Unleashing the Power of Bi-LSTM in Sentiment Analysis for Cutting-Edge Stock Price Prediction-2023](https://ieeexplore.ieee.org/document/10392444/):
	- **1. Statistical Predictive Accuracy:**
	  We will measure the raw predictive power of each model using a suite of standard classification metrics that are robust to the class imbalance often found in financial data:  
	- **F1-Score:** The harmonic mean of precision and recall, providing a balanced measure of a model's accuracy.
	- **Area Under the ROC Curve (AUC-ROC):** A comprehensive metric that evaluates a model's ability to distinguish between positive and negative outcomes across all thresholds.
	- **Precision and Recall:** To understand the specific types of prediction errors the models make.
	    
	  Consistent improvement in these metrics by the Inferred and Combined models over the Baseline and Vocal models would provide strong evidence for the predictive power of silent sentiment [1](https://ieeexplore.ieee.org/document/10392444/).  
	    
	  **2. Economic Significance:**  
	  Beyond statistical accuracy, we will assess the practical value of our models by simulating a simple trading strategy based on their predictions. This will allow us to measure the economic significance of the information captured by our inferred factors. Key metrics will include:  
	- **Sharpe Ratio:** The primary measure of risk-adjusted return. A higher Sharpe Ratio indicates a more favorable return for the amount of risk taken.
	- **Maximum Drawdown (MDD):** Measures the largest peak-to-trough decline in the strategy's portfolio value, serving as a key indicator of downside risk.
	    
	  Demonstrating a superior Sharpe Ratio would indicate that our inferred sentiment factors provide a tangible edge for investment decision-making.  
	    
	  By employing this systematic evaluation framework, this research will provide clear, empirical evidence on whether decoding the sentiment of the silent majority offers a new and valuable source of predictive power for financial markets.  
